import os
import clip
import torch
from PIL import Image
from torch.utils.data import DataLoader, Dataset
import configparser

# Path to blackhole dir
config = configparser.ConfigParser()
config.read('config.ini')
blackhole_path = config.get('BLACKHOLE', 'path')


# 1. Load the CLIP model
device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)
model, preprocess = clip.load("RN50", device=device)

# 2. Define the folder containing images
image_folder = f"{blackhole_path}real_vs_fake/real-vs-fake/test/fake"
batch_size = 8  # Adjust batch size based on your GPU memory

# 3. Custom dataset to load images from the folder
class ImageFolderDataset(Dataset):
    def __init__(self, folder_path, preprocess):
        self.folder_path = folder_path
        self.preprocess = preprocess
        self.image_files = [
            os.path.join(folder_path, f)
            for f in os.listdir(folder_path)
            if f.lower().endswith((".png", ".jpg", ".jpeg", ".bmp", ".gif"))
        ]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        image = Image.open(image_path).convert("RGB")  # Ensure images are RGB
        return self.preprocess(image), image_path  # Return preprocessed image and path

# Load dataset and dataloader
dataset = ImageFolderDataset(image_folder, preprocess)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

# 4. Define text prompts (e.g., for classification)
# text_prompts = ["Real Person", "Fake Person generated by GAN"]
text_prompts = ["a real photo", "an artificial image"]
text_tokens = clip.tokenize(text_prompts).to(device)

# 5. Process images in batches
print("Processing images...")
results = []  # To store results for all images
for batch_images, batch_paths in dataloader:
    batch_images = batch_images.to(device)
    
    with torch.no_grad():
        # Encode images and text
        image_features = model.encode_image(batch_images)
        text_features = model.encode_text(text_tokens)
        
        # Compute similarity and probabilities
        logits_per_image = image_features @ text_features.T
        probs = logits_per_image.softmax(dim=-1).cpu().numpy()
    
    # Save results for each image in the batch
    for i, path in enumerate(batch_paths):
        result = {prompt: probs[i][j] for j, prompt in enumerate(text_prompts)}
        result["image_path"] = path
        results.append(result)

# 6. Display results
print("Results:")
real_count = 0
fake_count = 0


for result in results:
    print(f"Image: {result['image_path']}")
    for prompt, prob in result.items():
        if prompt != "image_path":
            if prompt == text_prompts[0]:
                if prob > 0.5 : real_count+=1 
                else : fake_count+=1 
            print(f"  {prompt}: {prob:.4f}")

print(f"Classified as real: {real_count}")
print(f"Classified as fake: {fake_count}")